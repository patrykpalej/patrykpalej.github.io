[
  
  {
    "title": "Scripts automation on Linux",
    "url": "/posts/scripts-automation/",
    "categories": "Knowledge, Toolkit",
    "tags": "tools, mid-level",
    "date": "2024-04-07 00:00:00 +0200",
    





    
    "snippet": "A common issue in projects regarding data acquisition or frequently run scripts is the need to automate these processes. There area various methods to achieving this. The most common one is crontab...",
    "content": "A common issue in projects regarding data acquisition or frequently run scripts is the need to automate these processes. There area various methods to achieving this. The most common one is crontab. As an alternative, Windows users can utilize Windows Task Scheduler which is a desktop application for running specific executables  after a predefined trigger.For example purposes, let‚Äôs consider a bash script my_scipt.sh located in the user directory.crontabcrontab (short for ‚Äúcron table‚Äù), is a time-based job scheduler in Unix-like operating systems. It allows users to schedule jobs (commands or scripts) to run periodically at fixed times, dates, or intervals.Creating a Cron JobTo schedule a task using crontab, begin by creating a file in a location of your choice, under any name you prefer. Now, you can add entries for each job you want to schedule. A crontab file entry looks like this:* * * * * ~/my_script.shwhere each asterisk position corresponds to subsequentially:  minutes  hours  days of the month  months  weekdaysThe asterisk means ‚ÄúEVERY minute/hour/day/‚Ä¶‚Äù. Instead, you can type a specific number (or numbers, separated by a comma) which indicate when the script is about to start. For example, to run the script at 5:34 PM, on the first and fifteenth day of each month, you need to enter:34 17 1,15 * * ~/my_script.shFinally, to apply changes in the crontab file, run the following command in your terminal:crontab /path/to/crontab/file"
  },
  
  {
    "title": "Rounding algorithms in Python",
    "url": "/posts/rounding/",
    "categories": "Knowledge, Dev",
    "tags": "basics, python",
    "date": "2024-03-04 00:00:00 +0100",
    





    
    "snippet": "To round a number in Python you can use the round() function. It‚Äôs straightforward, but there is a nuance to be aware of. When you pass a number that is exactly halfway between two integers to this...",
    "content": "To round a number in Python you can use the round() function. It‚Äôs straightforward, but there is a nuance to be aware of. When you pass a number that is exactly halfway between two integers to this function, its behavior might be surprising:round(1.5)# 2round(2.5)# 2This happens because round() employs an algorithm known as bankers‚Äô rounding (BR), instead of arithmetic rounding (AR). The key distinction between these algorithms is that for numbers of the form x + 0.5, where x is even, BR rounds the number down, not up, as it would be with AR.The reasony why to use bankers‚Äô roundingWhen you want to round a single number, using BR algorithm might seem to have no sense, because it appears indeterministic. However, BR becomes advantageous for rounding a large set of numbers due to its statistical benefits. Consider the following set of measurements:1, 3, 2.5, 5.5, 6.5, 4, 1.5, 8Summing them up and calculating the average yields 32/8 = 4.If we round each value using (AR) before calculating the average, the result changes to 34/8 = 4.25.There is no objective reason why a number ending in .5 should always be rounded up. Statistically, such numbers should be rounded up and down with 50% probability. BR algorithm ensures this.Available workaroundsOne of the workarounds to achieve AR in Python is using int(x+0.5) instead of round(x). This method is straightforward, but the formula becomes more complex when you want to round the number to n digits. For instance, to imitate round(x, n), the formula is:int(x + 10**n + 0.5) / 10**nAnother workaround requires using decimal library:from decimal import Decimalx = 1.556precision = Decimal('0.00')float(Decimal(x).quantize(precision))# 1.56"
  },
  
  {
    "title": "Missing data in machine learning",
    "url": "/posts/missing-data/",
    "categories": "Knowledge, Data",
    "tags": "mid-level, machine-learning, data-science",
    "date": "2024-02-01 00:00:00 +0100",
    





    
    "snippet": "One of the most common issues regarding training machine learning models is dealing with missing data. This problem isn‚Äôt just about having less information to feed the model, but also that many ma...",
    "content": "One of the most common issues regarding training machine learning models is dealing with missing data. This problem isn‚Äôt just about having less information to feed the model, but also that many machine learning algorithms can‚Äôt handle missing data. In this article, I‚Äôm going to give a quick overview of the most important issues related to this topic.Which models accept missing data?Out of the most common machine learning algorithms, like: decision trees (+ their ensembles), linear models, SVM, KNN etc. only decision trees support using missing data. At least in scikit-learn implementation. When using any other algorithm, we must remove NaN values first. The most common methods for this are:  imputation  deletionNature of missing dataBefore proceeding to these methods, let‚Äôs first understand the nature and patterns in the missing data. Identifying why the data is missing is crucial in choosing the right strategy for handling it. Broadly, missing data can be categorized into three types:  Missing Completely At Random (MCAR)  Missing At Random (MAR)  Missing Not At Random (MNAR)Let‚Äôs dive into all of these categories, considering a case of a survey in which you are asked to provide various details about you, including your income.MCARThis type of NaN values occurs when the absence of data is completely independent of any other data, implying that the reasons for the missing values are entirely random and have no relation to the dataset.Example:Some respondents skipped this question because of missing it. They didn‚Äôt omit the question by intentention.MARMissing At Random occurs when the missingness of data in one feature is related to other features in the dataset, but not to the missing value itself. In other words, while the data is not missing completely at random, the tendency for a data point to be missing is only related to some of the observed data.Example:Younger respondents may be more open to disclosing their incomes, while older ones might consider such information confidential.MNARMissing Not At Random occurs when the missingness is related to the unobserved data itself. In other words, there is a reason related to the missing data which influences its absence.Example: High-income individuals might intentionally skip the income question due to privacy concerns. Here, the tendency to omit the income information is directly related to the income value itself.Meaning of the missing dataThere is also another dichotomy of NaN values which regards their meaning. We distinguish the following categories:  informative missing data  non-informative missing dataInformative missing data occurs when the absence of a value itself provides some insights.For example, if there is a missing value for the ‚ÄúUniversity Degree‚Äù field, it may indicate that the individual did not obtain a degree from any university. This conveys a specific information.Non-informative missing data happens when the absence of data does not convey any additional information about the dataset. This typically happens in situations where data is missing completely at random, without any underlying pattern or reason related to the data itself.For example, if there is a NaN value for age, we cannot determine the reason for this missingness, as in fact there is always an actual value for this feature.How to deal with missing data?As stated before, there are two main ways of handling missing data:  imputation (assigning a value in place of a NaN)  deletionMain reasons to choose imputation:  The occurrence of missing values is a natural process, and the model should be able to handle them  We can explain the nature of the missingness, thus we can substitute it with a specific value  Missing data occur in many rows, and we do not want to remove a significant portion of the data  The dataset has many important features, but only a few contain empty valuesMain reasons to choose deletion:  Data is Missing Completely At Random and it‚Äôs not going to happen on a regular basis  The presence of NaN values is marginal, and their deletion will not significantly impact the size of the datasetHave in mind, that usually deletion means deleting rows with NaN values. However, if there is a feature with a lot of missing data, it might be better to delete the whole column.Methods of imputationWhile deleting data is a simple process, imputation is definitely more complex. There are multiple methods of imputation, such as:Imputing a specific valueSometimes, understanding the nature of a NaN allows for a logical explanation. For example, if there is missing data for the question ‚ÄúHow many cigarettes do you smoke a day?‚Äù and it is known that the person is a non-smoker, we can reasonably impute the value as 0.Imputing a calculated valueFor categoric features we may impute the most frequent category in the dataset, as it‚Äôs the most likely value.For numeric features we may impute the mean or median, as it‚Äôs the most representative value for that feature. Imputing the mean works well for symmetrically distributed data, where the mean provides a good central estimate. However, in skewed distributions, the median is often a better choice as it is less affected by outliers.Imputing a value calculated in a subsetWhen calculating mean, median or mode, we can use only a subset of the whole dataset which consists of the most similar observations in terms of some other features.Training a model for estimating the missing valuesTraining an auxiliary model to estimate missing data is a sophisticated approach that involves using existing data to predict absent values. For instance, a regression model could be used for estimating continuous numeric data, whereas a classification model might be appropriate for categoric data.This approach may not always be optimal, as it can lead to an increase in the computational complexity of the overall problem."
  },
  
  {
    "title": "ü¶æ Asystenci AI do kodowania",
    "url": "/posts/ai-coding-assistants/",
    "categories": "Projects, Edu",
    "tags": "ai",
    "date": "2024-01-12 00:00:00 +0100",
    





    
    "snippet": "Projekt zawiera asystent√≥w AI, kt√≥re stworzy≈Çem, aby pom√≥c Ci w konkretnych zadaniach podczas nauki programowania. Obecnie dostƒôpny jest jeden asystent, ale w przysz≈Ço≈õci planujƒô dodaƒá kolejne.GPT ...",
    "content": "Projekt zawiera asystent√≥w AI, kt√≥re stworzy≈Çem, aby pom√≥c Ci w konkretnych zadaniach podczas nauki programowania. Obecnie dostƒôpny jest jeden asystent, ale w przysz≈Ço≈õci planujƒô dodaƒá kolejne.GPT coding mentorTen asystent pomaga w rozwiƒÖzywaniu zada≈Ñ programistycznych poprzez naprowadzanie Ciƒô na w≈Ça≈õciwe rozwiƒÖzanie, zamiast pisania kodu za Ciebie."
  },
  
  {
    "title": "Markdown language",
    "url": "/posts/markdown/",
    "categories": "Knowledge, Toolkit",
    "tags": "basics, tools",
    "date": "2024-01-07 00:00:00 +0100",
    





    
    "snippet": "OverviewMarkdown is a simple language used for text formatting. It allows you to obtain an elegant, visually attractive text just by writing a plain text document. It‚Äôs widely used due to its simpl...",
    "content": "OverviewMarkdown is a simple language used for text formatting. It allows you to obtain an elegant, visually attractive text just by writing a plain text document. It‚Äôs widely used due to its simplicity and ease of use, making it a popular choice for:  creating documentation  writing blog posts  text formatting in various applications, e.g. Jupyter Notebookand more.Markdown syntax covers many common text formatting elements, such as:  headings  bullet lists  links  images embedding  bold, italic  code formattingand much more.Use casesBelow you can find some examples of tools and services which support Markdown:  Jupyter Notebook / Jupyter Lab  static sites generators (blogs, documentations, this website etc.)  README files in Git repositories  note taking apps (Notion, Obsidian etc.)Basic syntaxIf you want to learn Markdown, check out https://www.markdownguide.org/ website.Below I listed the most common Markdown syntax elements:1. HeadingsRaw text:# First heading (H1)## Second heading (H2)### Third heading (H3)Preview:First heading (H1)Second heading (H2)Third heading (H3)2. Bullet listsRaw text:- first item- second item- third itemPreview:  first item  second item  third item3. LinksRaw text:[Click this](https://patrykpalej.dev)Preview:Click this4. ImagesRaw text:![image alt text](https://s3.dualstack.us-east-2.amazonaws.com/pythondotorg-assets/media/community/logos/python-logo-only.png)Preview:5. Bold, italicRaw text:**bold text***italic text*_also italic text_***bold and italic text***Preview:bold textitalic textalso italic textbold and italic text"
  },
  
  {
    "title": "Virtual environments in Python",
    "url": "/posts/virtualenv/",
    "categories": "Knowledge, Toolkit",
    "tags": "basics, tools, python",
    "date": "2023-12-30 00:00:00 +0100",
    





    
    "snippet": "1. What is it?Virtual environment (virtualenv in short) is a common way of managing installed packages in your Python project.2. Why do I need it?Using virtual environments allows you to separate y...",
    "content": "1. What is it?Virtual environment (virtualenv in short) is a common way of managing installed packages in your Python project.2. Why do I need it?Using virtual environments allows you to separate your projects from each other. Packages installed in one environment are not visible in other projects. Therefore, you can handle using different versions of various libraries in your projects. Additionally the environment is lighter if it contains only the packages that are used.3. How to use it?First and foremost ‚Äì in a terminal/command prompt.InstallationIf you don‚Äôt have virtualenv package installed, open your terminal/command prompt and run:pip install virtualenvInitializationIn your directory of choice (execute: cd path/to/directory) create the environment. Depending on how you installed virtualenv, you can try one of the following:virtualenv my_venvpython -m venv my_venv  Note that a conventional name for a virtual environment is venv, not my_venvActivationAfter creating a new virtualenv it needs to be activated first. To activate it, run:source my_venv/bin/activate  # for Linux or Mac.\\my_venv\\Scripts\\activate  # for WindowsAfter activation you‚Äôll see name of the environment in brackets at the beginning of line in terminal:(my_venv) your_user:path/to/directory$  If you want to deactivate the environment, just run deactivate.Installing packagesOnly after activating the environment you can install packages to it. Do it using pip install, e.g.:pip install numpyAll libs you install are downloaded to your virtualenv in my_venv/lib directory.Freezing virtualenvIf you want to share the project, don‚Äôt send my_venv folder to anyone. Instead, you need to freeze your environment by saving its state to a .txt file, conventionally named requirements.txt:pip freeze &gt; requirements.txtNow anyone can recreate the environment by creating a new one first and then installing everything from requirements.txt:pip install -r requirements.txt4. SummaryThe workflow of virtual environments is the following:virtualenv venv  # create a virtual environment named \"venv\"source venv/bin/activate  # activate venv on Linux or Mac./venv/Scripts/activate  # activate venv on Windowspip install &lt;package_name&gt;  # install required packagespip freeze &gt; requirements.txt  # dump state of your environment to a .txt filepip install -r requirements.txt  # recreate the environment from file (after creating a new one) AlternativesThere are some alternatives for using virtualenv which are worth checking:  Anaconda ‚Äì used mainly in data science, allows you to store all you need in a one big environment which can be separated from the pure Python interpreter on your machine  Poetry  Pipenv"
  },
  
  {
    "title": "Python Roadmap",
    "url": "/posts/roadmap/",
    "categories": "Knowledge, General",
    "tags": "python, data-science, web-development, basics, mid-level, advanced",
    "date": "2023-12-29 00:00:00 +0100",
    





    
    "snippet": "graph TD    A[START] --&gt;|code| beg_code_1[Language basics]    beg_code_1 --&gt; beg_code_2[Data structures]    beg_code_2 --&gt; beg_code_3[Conditional statements]    beg_code_3 --&gt; beg_code_...",
    "content": "graph TD    A[START] --&gt;|code| beg_code_1[Language basics]    beg_code_1 --&gt; beg_code_2[Data structures]    beg_code_2 --&gt; beg_code_3[Conditional statements]    beg_code_3 --&gt; beg_code_4[Loops]     beg_code_4 --&gt; beg_code_5[Functions]     beg_code_5 --&gt; beg_code_6[Error handling]     beg_code_6 --&gt; beg_code_7[Modules and packages]     beg_code_7 --&gt; beg_code_8[Basic OOP]     beg_code_8 --&gt; beg_code_9[File operations]     beg_code_9 --&gt; B[BEGINNER LEVEL]     A --&gt; |tools and data formats| beg_tools_1[\"IDE (PyCharm / VS Code)\"]    beg_tools_1 --&gt; beg_tools_2[Jupyter Notebook]    beg_tools_2 --&gt; beg_tools_3[Virtual environment]    beg_tools_3 --&gt; beg_tools_4[Basic Linux]    beg_tools_4 --&gt; beg_tools_5[Git]    beg_tools_5 --&gt; beg_tools_6[JSON]    beg_tools_6 --&gt; beg_tools_7[Markdown]    beg_tools_7 --&gt; beg_tools_8[CSV]    beg_tools_8 --&gt; B       A --&gt;|good practices| beg_gp_1[Clean code]    beg_gp_1 --&gt; beg_gp_2[PEP 8]    beg_gp_2 --&gt; beg_gp_3[Docstrings]    beg_gp_3 --&gt; beg_gp_4[Type annotation]    beg_gp_4 --&gt; B            B --&gt; |python| mid_python_1[Datetime operations]    mid_python_1 --&gt; mid_python_2[Regular expressions]    mid_python_2 --&gt; mid_python_3[Generators and iterators]    mid_python_3 --&gt; mid_python_4[Unit testing]    mid_python_4 --&gt; mid_python_5[Logging]    mid_python_5 --&gt; mid_python_6[Command Line Interface]    mid_python_6 --&gt; mid_python_7[\"Package managers (poetry / pipenv)\"]    mid_python_7 --&gt; C[MID LEVEL]        B --&gt; |data science| mid_ds_1[Numpy]     mid_ds_1 --&gt; mid_ds_2[Pandas]    mid_ds_2 --&gt; mid_ds_3[Data visualization]    mid_ds_3 --&gt; mid_ds_4[Exploratory data analysis]    mid_ds_4 --&gt; mid_ds_5[Web dashboards]    mid_ds_5 --&gt; mid_ds_6[Statistics]    mid_ds_6 --&gt; mid_ds_7[Data cleaning]    mid_ds_7 --&gt; mid_ds_8[Regression algorithms]    mid_ds_8 --&gt; mid_ds_9[Classification algorithms]    mid_ds_9 --&gt; mid_ds_10[Clustering algorithms]    mid_ds_10 --&gt; mid_ds_11[Performance metrics]    mid_ds_11 --&gt; mid_ds_12[Overfitting handling]    mid_ds_12 --&gt; mid_ds_13[Time series analysis]    mid_ds_13 --&gt; C         B --&gt; |web development| mid_web_1[Basic HTML and CSS]     mid_web_1 --&gt; mid_web_2[HTTP protocol]    mid_web_2 --&gt; mid_web_3[Web scraping]    mid_web_3 --&gt; mid_web_4[SQL and databases]    mid_web_4 --&gt; mid_web_5[Object Relational Mapping]    mid_web_5 --&gt; mid_web_6[\"REST API (Flask/FastAPI/Django)\"]    mid_web_6 --&gt; C            C --&gt; |python| adv_python_1[Decorators]    adv_python_1 --&gt; adv_python_2[Multithreading and multiprocessing]    adv_python_2 --&gt; adv_python_3[\"Dunder methods (OOP)\"]    adv_python_3 --&gt; adv_python_4[\"Abstract classes (OOP)\"]    adv_python_4 --&gt; adv_python_5[\"Polymorphism (OOP)\"]    adv_python_5 --&gt; adv_python_6[Design patterns]    adv_python_6 --&gt; D[ADVANCED LEVEL]        C --&gt; |devops| adv_devops_1[Advanced Linux]    adv_devops_1 --&gt; adv_devops_2[Docker]    adv_devops_2 --&gt; adv_devops_3[Kubernetes]    adv_devops_3 --&gt; adv_devops_4[Cloud]    adv_devops_4 --&gt; D        C --&gt; |data science| adv_ds_1[PCA]    adv_ds_1 --&gt; adv_ds_2[Bagging and boosting]    adv_ds_2 --&gt; adv_ds_3[\"Artificial Neural Networks (perceptron)\"]    adv_ds_3 --&gt; adv_ds_4[Convolutional Neural Networks]    adv_ds_4 --&gt; adv_ds_5[Other NN architectures]    adv_ds_5 --&gt; adv_ds_6[Spark]    adv_ds_6 --&gt; D"
  },
  
  {
    "title": "Jupyter Notebook",
    "url": "/posts/jupyter-notebook/",
    "categories": "Knowledge, Toolkit",
    "tags": "basics, tools",
    "date": "2023-12-21 00:00:00 +0100",
    





    
    "snippet": "The most common way of writing Python code is using .py files. An alternative to .py are so called ‚Äúnotebooks‚Äù (extended with .ipynb) . They are not only another file format, but most of all a diff...",
    "content": "The most common way of writing Python code is using .py files. An alternative to .py are so called ‚Äúnotebooks‚Äù (extended with .ipynb) . They are not only another file format, but most of all a different philosophy of writing (not only) Python code.What is a notebook?A notebook (.ipynb file) is actually a JSON file which contains Python code (and/or Markdown text) organized in so called ‚Äúcells‚Äù. When you open the file in an editor that supportsthe .ipynb format you‚Äôll see something like this:After running a single code cell, it is sent to the IPython kernel and executed.Editors with notebook support  Jupyter Notebook  Jupyter Lab  Google Colab  PyCharm (read only in the free version)  Visual Studio Codeand more.Many .ipynb editors (especially when they use cloud) work in a browser.Notebook key features  code and text support  each cell of code (or Markdown text) can be run separately  order of cells doesn‚Äôt matter, order of running them does  keyboard shortcuts for actions like: adding and deleting cells, navigating through the notebook, executing codeApplicationsJupyter Notebook isn‚Äôt a universal code editor. It‚Äôs not well-suited for writing production code. However, there are numerous use cases where Jupyter proves to be a valuable tool, such as:  prototyping  experiments  data analysis  educationKeyboard shortcutsWhen you escape the cell (by pressing Esc, of course), you switch it to command mode. Now you can use a number of keyboard shortcuts which allow you to perform various operations on the cell, e.g.:  creating a new cell above (a) or below (b)  deleting a cell (double d)  moving between cells (arrow up ‚Üë, arrow down ‚Üì)  executing a cell (Shift + Enter / Ctrl + Enter / Alt + Enter)If you want to enter the cell again (switch to edit mode) ‚Äì press Enter."
  },
  
  {
    "title": "üî¢ Symulacje numeryczne",
    "url": "/posts/numerical-simulation/",
    "categories": "Projects, Dev",
    "tags": "math-modeling, mid-level",
    "date": "2023-12-20 00:00:00 +0100",
    





    
    "snippet": "Opis projektuProjekt zawiera zestaw symulacji numerycznych r√≥≈ºnych zjawisk, takich jak:  Oddzia≈Çywania grawitacyjne  Bitwa ludzi z zombieü™ê Symulacja grawitacjiW tej symulacji mo≈ºesz:  Ustawiƒá warun...",
    "content": "Opis projektuProjekt zawiera zestaw symulacji numerycznych r√≥≈ºnych zjawisk, takich jak:  Oddzia≈Çywania grawitacyjne  Bitwa ludzi z zombieü™ê Symulacja grawitacjiW tej symulacji mo≈ºesz:  Ustawiƒá warunki poczƒÖtkowe dla grupy punkt√≥w materialnych (‚Äúplanet‚Äù)          mo≈ºna je wprowadziƒá rƒôcznie lub zaimportowaƒá z pliku        Dostosowaƒá animacjƒô poprzez wyb√≥r element√≥w do wy≈õwietlenia          same planety      pole grawitacyjne      trajektorie planet        Okre≈õliƒá strategiƒô obs≈Çugi kolizji          anihilacja      zamro≈ºenie      odbicie        Ustawiƒá prƒôdko≈õƒá symulacjiMo≈ºesz tak≈ºe zapisaƒá logi i warunki poczƒÖtkowe do pliku, ale tylko podczas uruchamiania lokalnego.Przyk≈Çadowe animacjePoni≈ºej znajdziesz przyk≈Çadowe animacje z symulatora:      üßü‚Äç‚ôÇÔ∏è Ludzie vs. Zombie  W tej symulacji dwie grupy postaci walczƒÖ ze sobƒÖ o przetrwanie  Ka≈ºda postaƒá jest zdefiniowana przez zestaw cech, w tym wsp√≥≈Çrzƒôdne (x, y), prƒôdko≈õƒá i si≈Çƒô  Gdy zombie wygra walkƒô, przekszta≈Çca cz≈Çowieka w nowego zombie. Je≈õli jednak cz≈Çowiek zwyciƒô≈ºy, eliminuje swojego zombie-przeciwnikaPrzyk≈Çadowe animacjePoni≈ºej znajdziesz przyk≈Çadowe animacje bitwy. Ludzie sƒÖ pomara≈Ñczowi,a zombie zielone.    "
  },
  
  {
    "title": "üèòÔ∏è Analiza rynku nieruchomo≈õci",
    "url": "/posts/real-estate-market-analysis/",
    "categories": "Projects, Dev",
    "tags": "web-scraping, data-visualization, machine-learning, cli",
    "date": "2023-11-30 00:00:00 +0100",
    





    
    "snippet": "Opis projektuW tym projekcie stworzy≈Çem system do zbierania i analizy ofert nieruchomo≈õci. G≈Ç√≥wnym celem jest oszacowanie warto≈õci rynkowej r√≥≈ºnych typ√≥w nieruchomo≈õci: dom√≥w, dzia≈Çek i mieszka≈Ñ. P...",
    "content": "Opis projektuW tym projekcie stworzy≈Çem system do zbierania i analizy ofert nieruchomo≈õci. G≈Ç√≥wnym celem jest oszacowanie warto≈õci rynkowej r√≥≈ºnych typ√≥w nieruchomo≈õci: dom√≥w, dzia≈Çek i mieszka≈Ñ. Projekt sk≈Çada siƒô z czterech etap√≥w:  scraping danych  wizualizacja danych  model ML do estymacji cen  API dla modelu (w trakcie)Wszystkie dane sƒÖ zbierane wy≈ÇƒÖcznie w celach edukacyjnych i nie sƒÖ wykorzystywane komercyjnie. Dane osobowe nie sƒÖ przechowywane.Scraping danychDane w tym projekcie pochodzƒÖ z dw√≥ch ≈∫r√≥de≈Ç:  https://www.otodom.pl/  https://www.domiporta.pl/Dla ka≈ºdego z nich uwzglƒôdniane sƒÖ trzy typy nieruchomo≈õci:  domy  dzia≈Çki  mieszkaniaProces scrapingu jest zaimplementowany przy u≈ºyciu klas abstrakcyjnych i dziedziczenia wed≈Çug poni≈ºszego schematu:flowchart LR    classDef abstractClass fill:#4444ffee, color:#fffc;        PropertyScraper --&gt; OtodomScraper    PropertyScraper --&gt; DomiportaScraper    OtodomScraper --&gt; OtodomHouseScraper    OtodomScraper --&gt; OtodomLandScraper    OtodomScraper --&gt; OtodomApartmentScraper    DomiportaScraper --&gt; DomiportaHouseScraper    DomiportaScraper --&gt; DomiportaLandScraper    DomiportaScraper --&gt; DomiportaApartmentScraper        class PropertyScraper,OtodomScraper,DomiportaScraper abstractClass;     Ka≈ºda konkretna (nieabstrakcyjna) klasa odpowiada jednej tabeli w relacyjnej bazie danych, w kt√≥rej zapisywane sƒÖ dane. Ponadto proces scrapingu jest podzielony na dwie oddzielne czƒô≈õci. Dla ka≈ºdej kombinacji ≈∫r√≥d≈Ça danych i typu nieruchomo≈õci (np. mieszkania z Otodom), proces pozyskiwania danych sk≈Çada siƒô z:  wyszukiwania ofert na podstawie za≈Ço≈ºonych filtr√≥w i zapisywania adres√≥w URL w bazie Redis  scrapowania ofert odpowiadajƒÖcych tym adresom URL i zapisywania ich w bazie danychWszystkie klasy scrapujƒÖce sƒÖ orkiestrowane przez narzƒôdzie CLI (Command Line Interface), kt√≥re umo≈ºliwia wygodne uruchamianie odpowiedniego scrapera. Na przyk≈Çad, mo≈ºesz wyszukaƒá URL-e mieszka≈Ñ z Otodom przez:python orchestrator.py search otodom apartmentsLub zescrapowaƒá oferty dzia≈Çek z Domiporta przez:python orchestrator.py scrape domiporta landsDla ka≈ºdej konkretnej klasy scrapujƒÖcej proces ETL dzia≈Ça zgodnie z poni≈ºszym schematem. Dla cel√≥w przyk≈Çadowych rozwa≈ºam OtodomApartmentScraper:flowchart TB    subgraph SEARCH      Crontab1[Crontab job]  --&gt; |RUN| Python1[python orchestrator.py search otodom apartments]      Python1 --&gt; |USE| OAS1[OtodomApartmentScraper class]      OAS1 --&gt; |SAVE| Redis[URLs on Redis]    end        subgraph SCRAPE      Crontab2[Crontab job] --&gt; |RUN| Python2[python orchestrator.py scrape otodom apartments]      Python2 --&gt; |LOAD| Redis      Redis --&gt; |USE| OAS2[OtodomApartmentScraper class]      OAS2 --&gt; |SAVE| Postgres[PostgreSQL database]    endWizualizacja danychPo zako≈Ñczeniu procesu pozyskiwania danych przechodzimy do czƒô≈õci wizualizacyjnej. W tym celu stworzy≈Çem dashboard webowy, kt√≥ry zawiera interaktywne wykresy.Na dashboardzie znajdziesz:  Rozk≈Çady:          powierzchni dom√≥w/dzia≈Çek/mieszka≈Ñ      ceny i ceny za metr kwadratowy      liczby ofert w r√≥≈ºnych regionach        Zmiany w czasie:          liczby oferowanych nieruchomo≈õci      ≈õredniej ceny        Mapƒô z zaznaczonymi lokalizacjami nieruchomo≈õcii wiele wiƒôcej. Poni≈ºej znajdziesz przyk≈Çadowe wykresy dla:DomyDzia≈ÇkiMieszkaniaTrenowanie modeluW poczƒÖtkowym podej≈õciu modele ML by≈Çy trenowane wy≈ÇƒÖcznie na danych z Otodom, poniewa≈º ten serwis dostarcza wiƒôcej informacji o nieruchomo≈õciach. Dla ka≈ºdego typu nieruchomo≈õci stworzony zosta≈Ç dedykowany model Random Forest Regressor przy u≈ºyciu Pipeline z scikit-learn. Przed trenowaniem modelu przeprowadzony zosta≈Ç proces feature engineering w celu przygotowania danych.Kroki preprocessingu na przyk≈Çadzie danych o domach obejmujƒÖ:  Przekszta≈Çcenie typu og≈Çoszenia (agencja lub prywatne) na warto≈õƒá boolean  Przekszta≈Çcenie typu rynku (pierwotny lub wt√≥rny) na warto≈õƒá boolean  Label encoding dnia tygodnia i pory roku, w kt√≥rych zosta≈Ça dodana oferta  Obliczenie r√≥≈ºnicy czasu miƒôdzy ofertƒÖ a arbitralnie wybranym timestampem (2023-01-01), aby odzwierciedliƒá pozycjƒô oferty na osi czasu  Label encoding lokalizacji domu (wie≈õ/przedmie≈õcia/miasto)  One hot encoding wojew√≥dztwa i podregionu nieruchomo≈õciZar√≥wno do dalszego preprocessingu (skalowanie cech), jak i trenowania modelu, zastosowano grid search z nastƒôpujƒÖcymi parametrami:  StandardScaler(), MinMaxScaler() do skalowania cech  400, 500, 600 dla n_estimators  70, 80, 90 dla max_depthDodatkowo eksperymentowa≈Çem z ekstrakcjƒÖ cech, jednak to podej≈õcie skutkowa≈Ço pogorszeniem wydajno≈õci modelu.Finalny pipeline, skonfigurowany dla optymalnej wydajno≈õci pod wzglƒôdem mean absolute error (z u≈ºyciem walidacji krzy≈ºowej), zawiera nastƒôpujƒÖce elementy:Metryki obliczone dla ca≈Çego zbioru danych o domach:Mean absolute error [PLN]: 165599.68Mean absolute percentage error [%]: 25.7Wydajno≈õƒá modelu jest daleka od doskona≈Ço≈õci, na co wp≈Çywa wiele czynnik√≥w, w tym subiektywny charakter wyceny dom√≥w. Model dobrze radzi sobie z kluczowymi aspektami takimi jak lokalizacja czy wielko≈õƒá, ale r√≥≈ºnorodno≈õƒá detali wnƒôtrz stanowi wyzwanie. Dodatkowo model nie wykorzystuje wszystkich cech nieruchomo≈õci, co wp≈Çywa na jego dok≈Çadno≈õƒá. Ta wersja to poczƒÖtkowy krok w eksploracji mo≈ºliwo≈õci modelowania cen, z potencja≈Çem na przysz≈Çe ulepszenia. G≈Ç√≥wnym celem jest oszacowanie warto≈õci rynkowej, a nie stworzenie uniwersalnej formu≈Çy wyceny.API dla modeluAPI wykorzystuje spiklowane modele przechowywane na Google Cloud Storage. Wspiera dwa typy endpoint√≥w GET dla ka≈ºdego typu nieruchomo≈õci:  estimate_price_from_json  estimate_price_otodom_offerKod znajdziesz w podlinkowanym repozytorium. API nie jest zhostowane ze wzglƒôdu na du≈ºe zu≈ºycie pamiƒôci wynikajƒÖce z ≈Çadowania zserializowanych modeli."
  }
  
]

